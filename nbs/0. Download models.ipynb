{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d9c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp fetch_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f222bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "from fastcore.script import call_parse\n",
    "import whisperx\n",
    "import whisper\n",
    "from speechbrain.pretrained import EncoderClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c38c45",
   "metadata": {},
   "source": [
    "# Download models\n",
    "\n",
    "Download and cache all the models we might need for training and preprocessing. Run this first on a cluster node that has unlimited internet access.\n",
    "\n",
    "**Usage:**  \n",
    "```\n",
    "python -m whisperspeech.fetch_models\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ef67d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def load_whisperx(model, lang):\n",
    "    try:\n",
    "        whisperx.asr.load_model(model, \"cpu\", compute_type=\"float16\", language=lang)\n",
    "    except ValueError as exc:\n",
    "        print(exc.args[0])\n",
    "        if exc.args[0] != \"Requested float16 compute type, but the target device or backend do not support efficient float16 computation.\":\n",
    "            raise\n",
    "\n",
    "@call_parse\n",
    "def main():\n",
    "    whisper.load_model('base.en')\n",
    "    whisper.load_model('small.en')\n",
    "    whisperx.vad.load_vad_model('cpu')\n",
    "    load_whisperx('medium.en', 'en')\n",
    "    load_whisperx('medium', 'en')\n",
    "    EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", savedir=\"~/.cache/speechbrain/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
